{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TNKjbL_UK_mZ"
      },
      "outputs": [],
      "source": [
        "!pip install split-folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MPhW9TFwqkDY"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ynjqU_QW7nxI"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Input, Lambda, Dense, Flatten,Dropout\n",
        "from keras.models import Model\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.applications.resnet import ResNet50\n",
        "from keras.applications.resnet import preprocess_input\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "import math\n",
        "from numpy import save,load\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "Path(\"/content/dataset/train/male\").mkdir(parents=True, exist_ok=True)\n",
        "Path(\"/content/dataset/test/male\").mkdir(parents=True, exist_ok=True)\n",
        "Path(\"/content/dataset/train/female\").mkdir(parents=True, exist_ok=True)\n",
        "Path(\"/content/dataset/test/female\").mkdir(parents=True, exist_ok=True)\n",
        "Path(\"/content/dataset_2\").mkdir(parents=True, exist_ok=True)\n",
        "import splitfolders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lb97Os4QYHnb"
      },
      "outputs": [],
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D-4cqfTLBPGm"
      },
      "outputs": [],
      "source": [
        "splitfolders.ratio('/content/drive/MyDrive/Colab Notebooks/NewTrain4K/', output=\"/content/dataset_2/\", seed=1337, ratio=(.8,0.1,0.1)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bG9Nrthv8PI-"
      },
      "outputs": [],
      "source": [
        "! ls /content/dataset_2/train/Male | wc -l\n",
        "! ls /content/dataset_2/test/Male | wc -l\n",
        "\n",
        "! ls /content/dataset_2/train/Female | wc -l\n",
        "! ls /content/dataset_2/test/Female | wc -l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5jkJSrOnIcHm"
      },
      "outputs": [],
      "source": [
        "#generating data using the data directory\n",
        "train_data_dir = '/content/dataset_2/train'\n",
        "test_data_dir = '/content/dataset_2/test'\n",
        "val_data_dir = '/content/dataset_2/val'\n",
        "BATCH_SIZE=8 \n",
        "class_subset = sorted(os.listdir('/content/drive/MyDrive/Colab Notebooks/NewTrain4K'))[:10] # Using only the first 10 classes\n",
        "print(class_subset)\n",
        "train_generator = ImageDataGenerator(rotation_range=90, \n",
        "                                     brightness_range=[0.1, 0.7],\n",
        "                                     width_shift_range=0.5, \n",
        "                                     height_shift_range=0.5,\n",
        "                                     horizontal_flip=True, \n",
        "                                     vertical_flip=True,\n",
        "                                     validation_split=0.15,\n",
        "                                     preprocessing_function=preprocess_input) # VGG16 preprocessing\n",
        "\n",
        "test_generator = ImageDataGenerator(preprocessing_function=preprocess_input) # VGG16 preprocessing\n",
        "\n",
        "traingen = train_generator.flow_from_directory(train_data_dir,\n",
        "                                               target_size=(128, 128),\n",
        "                                               class_mode='categorical',\n",
        "                                               classes=class_subset,\n",
        "                                               subset='training',\n",
        "                                               batch_size=BATCH_SIZE, \n",
        "                                               shuffle=True,\n",
        "                                               seed=42)\n",
        "\n",
        "validgen = train_generator.flow_from_directory(val_data_dir,\n",
        "                                               target_size=(128, 128),\n",
        "                                               class_mode='categorical',\n",
        "                                               classes=class_subset,\n",
        "                                               subset='validation',\n",
        "                                               batch_size=BATCH_SIZE,\n",
        "                                               shuffle=True,\n",
        "                                               seed=42)\n",
        "\n",
        "testgen = test_generator.flow_from_directory(test_data_dir,\n",
        "                                             target_size=(224, 224),\n",
        "                                             class_mode=None,\n",
        "                                             classes=class_subset,\n",
        "                                             batch_size=1,\n",
        "                                             shuffle=False,\n",
        "                                             seed=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xp9aFhQCI9Sb"
      },
      "outputs": [],
      "source": [
        "# using transfer learning with the help of VGG model\n",
        "def create_VGG_Based_model(input_shape, n_classes, optimizer='rmsprop', fine_tune=0):\n",
        "    conv_base = VGG16(include_top=False,\n",
        "                     weights='imagenet', \n",
        "                     input_shape=input_shape)\n",
        "    if fine_tune > 0:\n",
        "        for layer in conv_base.layers[:-fine_tune]:\n",
        "            layer.trainable = False\n",
        "    else:\n",
        "        for layer in conv_base.layers:\n",
        "            layer.trainable = False\n",
        "    top_model = conv_base.output\n",
        "    top_model = Flatten(name=\"flatten\")(top_model)\n",
        "    top_model = Dense(4096, activation='relu')(top_model)\n",
        "    top_model = Dense(1072, activation='relu')(top_model)\n",
        "    top_model = Dropout(0.2)(top_model)\n",
        "    output_layer = Dense(n_classes, activation='softmax')(top_model)\n",
        "    model = Model(inputs=conv_base.input, outputs=output_layer)\n",
        "\n",
        "    model.compile(optimizer=optimizer, \n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zal5eSyhJPIc"
      },
      "outputs": [],
      "source": [
        "input_shape = (128, 128, 3)\n",
        "optim_1 = Adam(learning_rate=0.001)\n",
        "n_classes=2\n",
        "\n",
        "n_steps = traingen.samples // BATCH_SIZE\n",
        "n_val_steps = validgen.samples // BATCH_SIZE\n",
        "n_epochs = 50\n",
        "\n",
        "vgg_model = create_VGG_Based_model(input_shape, n_classes, optim_1, fine_tune=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jpfAbYneJvY0"
      },
      "outputs": [],
      "source": [
        "! pip install livelossplot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DcxCUuFUJqAZ"
      },
      "outputs": [],
      "source": [
        "from livelossplot.inputs.keras import PlotLossesCallback\n",
        "\n",
        "plot_loss_1 = PlotLossesCallback()\n",
        "\n",
        "# ModelCheckpoint callback - save best weights\n",
        "tl_checkpoint_1 = ModelCheckpoint(filepath='/content/drive/MyDrive/ENEL645/savedmodels/vgg16_model_v4k_20220402.weights.best.hdf5',\n",
        "                                  save_best_only=True,\n",
        "                                  verbose=1)\n",
        "\n",
        "# EarlyStopping\n",
        "early_stop = EarlyStopping(monitor='val_loss',\n",
        "                           patience=10,\n",
        "                           restore_best_weights=True,\n",
        "                           mode='min')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "JnHKc79QJ8LB"
      },
      "outputs": [],
      "source": [
        "%%time \n",
        "\n",
        "vgg_history = vgg_model.fit(traingen,\n",
        "                            batch_size=BATCH_SIZE,\n",
        "                            epochs=n_epochs,\n",
        "                            validation_data=validgen,\n",
        "                            steps_per_epoch=n_steps,\n",
        "                            validation_steps=n_val_steps,\n",
        "                            callbacks=[tl_checkpoint_1, early_stop, plot_loss_1],\n",
        "                            verbose=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#loading the pretraining model\n",
        "from keras.preprocessing import image\n",
        "model = tf.keras.models.load_model('/content/drive/MyDrive/ENEL645/savedmodels/vgg16_model_v4k_20220402.weights.best.hdf5')\n",
        "img_width, img_height = 128,128\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "fp1vd33I4RpZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_from_model(img,height,width,label):\n",
        "  img = image.load_img(img, target_size=(height,width))\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "  images = np.vstack([x])\n",
        "  classes = model.predict(images)\n",
        "  classes=np.argmax(classes,1)\n",
        "  print(label)\n",
        "  plt.imshow(img, cmap = \"gray\")\n",
        "  print(\"female:\"+str( len(np.where( classes == 0)[0])))\n",
        "  print(\"male:\"+str( len(np.where( classes == 1)[0])))\n"
      ],
      "metadata": {
        "id": "TuYAEAyx4VV5"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_from_model('/content/drive/MyDrive/Colab Notebooks/NewTrain/Male/0 (1).jpg',img_width,img_height,'Male Image')"
      ],
      "metadata": {
        "id": "DbI2mynT4ZZZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "vgg16_final",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}