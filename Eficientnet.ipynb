{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Input, Lambda, Dense, Flatten,Dropout\n",
        "from keras.models import Model\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow as tf\n",
        "from keras.applications.efficientnet import EfficientNetB1\n",
        "from keras.applications.efficientnet import preprocess_input\n",
        "import numpy as np\n",
        "import math\n",
        "from numpy import save,load\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "import os\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "Path(\"/content/dataset/train/male\").mkdir(parents=True, exist_ok=True)\n",
        "Path(\"/content/dataset/test/male\").mkdir(parents=True, exist_ok=True)\n",
        "Path(\"/content/dataset/train/female\").mkdir(parents=True, exist_ok=True)\n",
        "Path(\"/content/dataset/test/female\").mkdir(parents=True, exist_ok=True)\n",
        "Path(\"/content/dataset_2\").mkdir(parents=True, exist_ok=True)"
      ],
      "metadata": {
        "id": "ynjqU_QW7nxI"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install split-folders"
      ],
      "metadata": {
        "id": "5e43f09hUOD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import splitfolders\n",
        "splitfolders.ratio('/content/drive/MyDrive/Colab Notebooks/NewTrain4K/', output=\"/content/dataset_2/\", seed=1337, ratio=(.8,0.1,0.1)) "
      ],
      "metadata": {
        "id": "D-4cqfTLBPGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! ls /content/dataset_2/train/Male | wc -l\n",
        "! ls /content/dataset_2/test/Male | wc -l\n",
        "\n",
        "! ls /content/dataset_2/train/Female | wc -l\n",
        "! ls /content/dataset_2/test/Female | wc -l"
      ],
      "metadata": {
        "id": "bG9Nrthv8PI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_dir = '/content/dataset_2/train'\n",
        "test_data_dir = '/content/dataset_2/test'\n",
        "BATCH_SIZE=8\n",
        "class_subset = sorted(os.listdir('/content/dataset_2/test'))[:10] # Using only the first 10 classes\n",
        "train_generator = ImageDataGenerator(rotation_range=90, \n",
        "                                     brightness_range=[0.1, 0.7],\n",
        "                                     width_shift_range=0.5, \n",
        "                                     height_shift_range=0.5,\n",
        "                                     horizontal_flip=True, \n",
        "                                     vertical_flip=True,\n",
        "                                     validation_split=0.15,\n",
        "                                     preprocessing_function=preprocess_input) # efficientnet preprocessing\n",
        "\n",
        "test_generator = ImageDataGenerator(preprocessing_function=preprocess_input) # efficientnet preprocessing\n",
        "\n",
        "traingen = train_generator.flow_from_directory(train_data_dir,\n",
        "                                               target_size=(128, 128),\n",
        "                                               class_mode='categorical',\n",
        "                                               classes=class_subset,\n",
        "                                               subset='training',\n",
        "                                               batch_size=BATCH_SIZE, \n",
        "                                               shuffle=True,\n",
        "                                               seed=42)\n",
        "\n",
        "validgen = train_generator.flow_from_directory(train_data_dir,\n",
        "                                               target_size=(128, 128),\n",
        "                                               class_mode='categorical',\n",
        "                                               classes=class_subset,\n",
        "                                               subset='validation',\n",
        "                                               batch_size=BATCH_SIZE,\n",
        "                                               shuffle=True,\n",
        "                                               seed=42)\n",
        "\n",
        "testgen = test_generator.flow_from_directory(test_data_dir,\n",
        "                                             target_size=(224, 224),\n",
        "                                             class_mode=None,\n",
        "                                             classes=class_subset,\n",
        "                                             batch_size=1,\n",
        "                                             shuffle=False,\n",
        "                                             seed=42)\n",
        "print(class_subset)"
      ],
      "metadata": {
        "id": "5jkJSrOnIcHm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_efficientb1_Based_model(input_shape, n_classes, optimizer='rmsprop', fine_tune=0):\n",
        "  conv_base = EfficientNetB1(\n",
        "                    include_top=True,\n",
        "                    weights=\"imagenet\",\n",
        "                    input_tensor=None,\n",
        "                    input_shape=None,\n",
        "                    pooling=None,\n",
        "                    classes=1000,\n",
        "                    classifier_activation=\"softmax\",\n",
        "                )\n",
        "    if fine_tune > 0:\n",
        "        for layer in conv_base.layers[:-fine_tune]:\n",
        "            layer.trainable = False\n",
        "    else:\n",
        "        for layer in conv_base.layers:\n",
        "            layer.trainable = False\n",
        "    top_model = conv_base.output\n",
        "    top_model = Flatten(name=\"flatten\")(top_model)\n",
        "    top_model = Dense(4096, activation='relu')(top_model)\n",
        "    top_model = Dense(1072, activation='relu')(top_model)\n",
        "    top_model = Dropout(0.2)(top_model)\n",
        "    output_layer = Dense(n_classes, activation='softmax')(top_model)\n",
        "    \n",
        "    model = Model(inputs=conv_base.input, outputs=output_layer)\n",
        "\n",
        "    model.compile(optimizer=optimizer, \n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "Xp9aFhQCI9Sb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (256, 256, 3)\n",
        "optim_1 = Adam(learning_rate=0.001)\n",
        "n_classes=2\n",
        "\n",
        "n_steps = traingen.samples // BATCH_SIZE\n",
        "n_val_steps = validgen.samples // BATCH_SIZE\n",
        "n_epochs = 50\n",
        "\n",
        "res_model = create_efficientb1_Based_model(input_shape, n_classes, optim_1, fine_tune=0)"
      ],
      "metadata": {
        "id": "Zal5eSyhJPIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install livelossplot"
      ],
      "metadata": {
        "id": "jpfAbYneJvY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from livelossplot.inputs.keras import PlotLossesCallback\n",
        "\n",
        "plot_loss_1 = PlotLossesCallback()\n",
        "\n",
        "# ModelCheckpoint callback - save best weights\n",
        "tl_checkpoint_1 = ModelCheckpoint(filepath='/content/drive/MyDrive/ENEL645/savedmodels/efficientnet_model_v14K.weights.best.hdf5',\n",
        "                                  save_best_only=True,\n",
        "                                  verbose=1)\n",
        "\n",
        "# EarlyStopping\n",
        "early_stop = EarlyStopping(monitor='val_loss',\n",
        "                           patience=10,\n",
        "                           restore_best_weights=True,\n",
        "                           mode='min')"
      ],
      "metadata": {
        "id": "DcxCUuFUJqAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time \n",
        "\n",
        "efficientnet_history = res_model.fit(traingen,\n",
        "                            batch_size=BATCH_SIZE,\n",
        "                            epochs=n_epochs,\n",
        "                            validation_data=validgen,\n",
        "                            steps_per_epoch=n_steps,\n",
        "                            validation_steps=n_val_steps,\n",
        "                            callbacks=[tl_checkpoint_1, early_stop, plot_loss_1],\n",
        "                            verbose=1)\n"
      ],
      "metadata": {
        "id": "JnHKc79QJ8LB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import image\n",
        "model = tf.keras.models.load_model('/content/drive/MyDrive/ENEL645/savedmodels/efficientnet_model_v14K.weights.best.hdf5')\n",
        "img_width, img_height = 240,240\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "KQsS3nXfFBGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "img = image.load_img('/content/drive/MyDrive/Colab Notebooks/NewTrain/Male/0 (1).jpg', target_size=(img_width, img_height))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "images = np.vstack([x])\n",
        "classes = model.predict(images)\n",
        "classes=np.argmax(classes,1)\n",
        "print(\"Male Image\")\n",
        "print(\"female:\"+str( len(np.where( classes == 0)[0])))\n",
        "print(\"male:\"+str( len(np.where( classes == 1)[0])))\n",
        "plt.imshow(img, cmap = \"gray\")\n"
      ],
      "metadata": {
        "id": "yP_H2M2uFGbl"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Eficientnet",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}