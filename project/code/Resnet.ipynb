{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "7Aws9O4WZ3m2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "ynjqU_QW7nxI"
      },
      "outputs": [],
      "source": [
        "#importing necessary libraries\n",
        "from keras.layers import Input, Lambda, Dense, Flatten,Dropout\n",
        "from keras.models import Model\n",
        "\n",
        "from keras.applications.resnet import ResNet50\n",
        "from keras.applications.resnet import preprocess_input\n",
        "\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "import math\n",
        "from numpy import save,load\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "Path(\"/content/dataset_2\").mkdir(parents=True, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tACnjJnycKdC"
      },
      "outputs": [],
      "source": [
        "# data listing\n",
        "! ls '/content/drive/MyDrive/Colab Notebooks/NewTrain4K/' | wc -l\n",
        "! ls '/content/drive/MyDrive/Colab Notebooks/NewTrain4K/' | wc -l"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# intialising the GPU for training and testing purposes\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "metadata": {
        "id": "kqu8UyGLD4zX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-m0QqSZ6JyU"
      },
      "outputs": [],
      "source": [
        "#installing the library for spliting the data\n",
        "!pip install split-folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YTMlxf-PGG5N"
      },
      "outputs": [],
      "source": [
        "#mounting the drive to access the dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zto866Xq6EkA"
      },
      "outputs": [],
      "source": [
        "#spliting the data into training,testing and validation sets\n",
        "import splitfolders\n",
        "splitfolders.ratio('/content/drive/MyDrive/Colab Notebooks/NewTrain4K/', output=\"/content/dataset_2/\", seed=1337, ratio=(.8,0.1,0.1)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bG9Nrthv8PI-"
      },
      "outputs": [],
      "source": [
        "#listing the data to check\n",
        "! ls /content/dataset_2/train/Male | wc -l\n",
        "! ls /content/dataset_2/test/Male | wc -l\n",
        "\n",
        "! ls /content/dataset_2/train/Female | wc -l\n",
        "! ls /content/dataset_2/test/Female | wc -l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5jkJSrOnIcHm"
      },
      "outputs": [],
      "source": [
        "#preparing training, testing and validation sets\n",
        "train_data_dir = '/content/dataset_2/train'\n",
        "test_data_dir = '/content/dataset_2/test'\n",
        "BATCH_SIZE=8\n",
        "class_subset=[\"Female\",\"Male\"]\n",
        "train_generator = ImageDataGenerator(rotation_range=90, \n",
        "                                     brightness_range=[0.1, 0.7],\n",
        "                                     width_shift_range=0.5, \n",
        "                                     height_shift_range=0.5,\n",
        "                                     horizontal_flip=True, \n",
        "                                     vertical_flip=True,\n",
        "                                     validation_split=0.15,\n",
        "                                     preprocessing_function=preprocess_input) # preprocess function from resnet\n",
        "\n",
        "test_generator = ImageDataGenerator(preprocessing_function=preprocess_input) # preprocess function from resnet\n",
        "\n",
        "traingen = train_generator.flow_from_directory(train_data_dir,\n",
        "                                               target_size=(128, 128),\n",
        "                                               class_mode='categorical',\n",
        "                                               classes=class_subset, # class labels\n",
        "                                               subset='training',\n",
        "                                               batch_size=BATCH_SIZE, # single batch size\n",
        "                                               shuffle=True,\n",
        "                                               seed=42)\n",
        "\n",
        "validgen = train_generator.flow_from_directory(train_data_dir,\n",
        "                                               target_size=(128, 128),\n",
        "                                               class_mode='categorical',\n",
        "                                               classes=class_subset,\n",
        "                                               subset='validation',\n",
        "                                               batch_size=BATCH_SIZE,\n",
        "                                               shuffle=True,\n",
        "                                               seed=42)\n",
        "\n",
        "testgen = test_generator.flow_from_directory(test_data_dir,\n",
        "                                             target_size=(224, 224),\n",
        "                                             class_mode=None,\n",
        "                                             classes=class_subset,\n",
        "                                             batch_size=1,\n",
        "                                             shuffle=False,\n",
        "                                             seed=42)\n",
        "print(class_subset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xp9aFhQCI9Sb"
      },
      "outputs": [],
      "source": [
        "# applying the Transfer Learning using the resnet model\n",
        "def create_RESNET_Based_model(input_shape, n_classes, optimizer='rmsprop', fine_tune=0):\n",
        "    \"\"\"\n",
        "    Compiles a model integrated with resnet pretrained layers\n",
        "    \n",
        "    input_shape: (width, height, channels)\n",
        "      data type:tuple \n",
        "      descriotion: defines the shape of images\n",
        "    n_classes: \n",
        "      datatype: int\n",
        "      description: - defines the number of layer for output layers.\n",
        "    optimizer: \n",
        "      data type:string \n",
        "      description: instantiated optimizer to use for training. \n",
        "    fine_tune: \n",
        "      data type:int\n",
        "      description - The number of pre-trained layers to unfreeze.\n",
        "                If it is 0, all pretrained layers will freeze during training\n",
        "    \"\"\"\n",
        "    \n",
        "   # Include_top = False, will exclude the model's fully-connected layers.\n",
        "    conv_base = ResNet50(include_top=False,\n",
        "                     weights='imagenet', \n",
        "                     input_shape=input_shape)\n",
        "    if fine_tune > 0:\n",
        "        for layer in conv_base.layers[:-fine_tune]:\n",
        "            layer.trainable = False\n",
        "    else:\n",
        "        for layer in conv_base.layers:\n",
        "            layer.trainable = False\n",
        "\n",
        "    # Creating new fully connected layers\n",
        "    top_model = conv_base.output\n",
        "    top_model = Flatten(name=\"flatten\")(top_model)\n",
        "    top_model = Dense(4096, activation='relu')(top_model)\n",
        "    top_model = Dense(1072, activation='relu')(top_model)\n",
        "    top_model = Dropout(0.2)(top_model)\n",
        "    output_layer = Dense(n_classes, activation='softmax')(top_model)\n",
        "    \n",
        "    # combining the convolutional layer and new fully-connected layers into a Model object.\n",
        "    model = Model(inputs=conv_base.input, outputs=output_layer)\n",
        "\n",
        "    # Compiles the model.\n",
        "    model.compile(optimizer=optimizer, \n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zal5eSyhJPIc"
      },
      "outputs": [],
      "source": [
        "input_shape = (128, 128, 3)\n",
        "optim_1 = Adam(learning_rate=0.001)\n",
        "n_classes=2\n",
        "\n",
        "n_steps = traingen.samples // BATCH_SIZE\n",
        "n_val_steps = validgen.samples // BATCH_SIZE\n",
        "n_epochs = 10\n",
        "\n",
        "# Training the model without fine tuning\n",
        "res_model = create_RESNET_Based_model(input_shape, n_classes, optim_1, fine_tune=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jpfAbYneJvY0"
      },
      "outputs": [],
      "source": [
        "! pip install livelossplot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DcxCUuFUJqAZ"
      },
      "outputs": [],
      "source": [
        "from livelossplot.inputs.keras import PlotLossesCallback\n",
        "\n",
        "plot_loss_1 = PlotLossesCallback()\n",
        "\n",
        "# saving best weights\n",
        "tl_checkpoint_1 = ModelCheckpoint(filepath='/content/drive/MyDrive/ENEL645/savedmodels/resnet_model_v12konlymale.weights.best.hdf5',\n",
        "                                  save_best_only=True,\n",
        "                                  verbose=1)\n",
        "\n",
        "# EarlyStopping\n",
        "early_stop = EarlyStopping(monitor='val_loss',\n",
        "                           patience=10,\n",
        "                           restore_best_weights=True,\n",
        "                           mode='min')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JnHKc79QJ8LB"
      },
      "outputs": [],
      "source": [
        "%%time \n",
        "\n",
        "#training the model\n",
        "resnet_history = res_model.fit(traingen,\n",
        "                            batch_size=BATCH_SIZE,\n",
        "                            epochs=n_epochs,\n",
        "                            validation_data=validgen,\n",
        "                            steps_per_epoch=n_steps,\n",
        "                            validation_steps=n_val_steps,\n",
        "                            callbacks=[tl_checkpoint_1, early_stop, plot_loss_1],\n",
        "                            verbose=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3U8FQUFGU1vo"
      },
      "outputs": [],
      "source": [
        "#retraining the model for better accuracy\n",
        "model = tf.keras.models.load_model('/content/drive/MyDrive/ENEL645/savedmodels/resnet_model_v1no4k.weights.best.hdf5')\n",
        "model.trainable = True\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(lr = 1e-8),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "model.fit(traingen,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=n_epochs,\n",
        "          validation_data=validgen,\n",
        "          steps_per_epoch=n_steps,\n",
        "          validation_steps=n_val_steps,\n",
        "          callbacks=[tl_checkpoint_1, early_stop, plot_loss_1],\n",
        "          verbose=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wC9FrcP4UcHP"
      },
      "outputs": [],
      "source": [
        "#loading the pretraining model\n",
        "from keras.preprocessing import image\n",
        "model = tf.keras.models.load_model('/content/drive/MyDrive/ENEL645/savedmodels/resnet_model_v1no4k.weights.best.hdf5')\n",
        "img_width, img_height = 128,128\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#function for Predicting label for given image using the pretrained save model\n",
        "\n",
        "def predict_from_model(img,height,width,label):\n",
        "  img = image.load_img(img, target_size=(height,width))\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "  images = np.vstack([x])\n",
        "  classes = model.predict(images)\n",
        "  classes=np.argmax(classes,1)\n",
        "  print(label)\n",
        "  plt.imshow(img, cmap = \"gray\")\n",
        "  print(\"female:\"+str( len(np.where( classes == 0)[0])))\n",
        "  print(\"male:\"+str( len(np.where( classes == 1)[0])))\n",
        "\n"
      ],
      "metadata": {
        "id": "zXtyuCWMZdcp"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_from_model('/content/drive/MyDrive/Colab Notebooks/NewTrain/Female/0 (1).jpg',img_width,img_height,'Female Image')"
      ],
      "metadata": {
        "id": "WQVn8poLq7WC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# saved model link : https://drive.google.com/file/d/1dY83OdxIO7ae0mL7CKJExB1crWX144iX/view?usp=sharing"
      ],
      "metadata": {
        "id": "l1yZqVqmvOd3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Resnet",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}